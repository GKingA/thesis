%----------------------------------------------------------------------------
\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}\label{sect:Introduction}
%----------------------------------------------------------------------------

Summarization tasks are relevant in the field of natural language processing (NLP). Complex end-to-end models like Hierarchical Structured Self-Attentive Model (HSSAS) \cite{HSSAS} can construct great summaries, and the best model as of writing this thesis was \textit{Text Summarization with Pretrained Encoders}\cite{BERTsum} using BERT. I write about the background of this field in chapter~\ref{sect:Background}.

Graph neural networks on the other hand are not yet widely researched and their usage for NLP purposes has not been explored previously, at least to my knowledge. Graph Convolutional Networks (GCN) have been successfully applied on a variety of tasks recently, but not as widely as other methods.

That being said representing syntax with graphs or trees is common practice on the field, so finding a tool that is capable of generating graph representations from texts was not a hard task. I used the \textit{stanfordnlp} library which uses deep learning to determine part of speech (POS) tags, word lemmas and universal dependency (UD) relations between words.

I used these graphs to build one merged graph that can represent a set of sentences, like summaries and articles in a graph format. I had to modify the summary graphs further to have the same structure as the article graph. Chapter \ref{sect:DataProcessing} is about this process and the graph representation used in graph\_nets module. In chapter \ref{sect:GraphNetwork} I documented some of the most important parts of the graph\_nets library as well as relevant deep learning concepts.

Chapter \ref{sect:Models} focuses on the structure of the models used for my experiments during the semester. There are multiple model descriptions in the chapter, all of which I experimented with and I documented their results in chapter \ref{sect:Experiments}. The conclusion and my plans for future work are described in chapter \ref{sect:Future}. The code for the project is publicly available on \href{https://github.com/GKingA/graph\_transformations}{GitHub}.