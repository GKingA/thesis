%----------------------------------------------------------------------------
\chapter{Conclusion and future work}\label{sect:Future}
%----------------------------------------------------------------------------
I think we only started to explore the possible uses of this technique in the realms of natural language processing research and there is still a lot of open questions.

My plans for the future include further experiments with the preprocessing and optimization, but also the construction of a new model.

Modifications in the preprocessing step may include using word-embeddings as input features of the nodes, trying to use actual extracted summarizations as target graphs and constructing a target graph as the intersection of the extracted summarization and the human written summarization.

Trying to train the graph network only to learn which nodes to keep is also a viable option which might gives us better results.

I also plan to write a completely new model from scratch that incorporates self attention mechanism to further strengthen the influences inside the graph.