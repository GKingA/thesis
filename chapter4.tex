%----------------------------------------------------------------------------
\chapter{Experiments and results}\label{sect:Experiments}
%----------------------------------------------------------------------------
\section{Evaluation methods}

I used three methods to evaluate the results. The most basic method is the accuracy measure, which calculates the ratio of the correct answers as follows:

\[accuracy = \frac{correct\ answer}{all\ answer}\]

Since we are talking about graphs we need to measure the accuracy on the nodes and (if we are also training on them) the edges.
\[accuracy_{nodes\ and\ edges} = \frac{correct\ nodes + correct\ edges}{all\ nodes + all\ edges}\]

The other general evaluation metric in case of classification is the F-score. This is better for evaluating the results of a classification because it is not so greatly affected by the distribution of the classes. For this we need to calculate the true positive, true negative, false positive and false negative measures for every class. See on Figue~\ref{fig:TP_TN_FP_FN}.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=100mm, keepaspectratio]{figures/F_score.png}
	\caption{The visual representation of the concept of true positive, true negative, false positive and false negative measures.}
	\label{fig:TP_TN_FP_FN}
\end{figure}


\[TP_{node==0} = number\ of\ correctly\ guessed\ node==0\]
\[TN_{node==0} = number\ of\ correctly\ guessed\ node!=0\]
\[FP_{node==0} = number\ of\ incorrectly\ guessed\ node==0\]
\[FN_{node==0} = number\ of\ incorrectly\ guessed\ node!=0\]

With these measures we can calculate the precision and recall. The precision tells us the ratio of correct guesses of the class out of every time the model predicted that class. The recall is the ratio of the correct guesses out of every instance that are actually in the class. The harmonic mean of the precision and recall is the F-score.

\[precision = \frac{TP}{TP + FN}\]
\[recall = \frac{TP}{TP + FP}\]

\[F1 = 2 * \frac{precision * recall}{precision + recall}\]

I constructed extractive summaries from the resulting graphs and the original articles multiple ways described in section~\ref{ssect:ExperimnetsAndResults} and calculated the various ROUGE scores for each method's output.

\section{Experiments and results}\label{ssect:ExperimnetsAndResults}
I have experimented with both the Encode Process Decode and the Graph Attention Network models with varying success.
\subsection{Encode Process Decode}
At first I tried to get the Encode-Process-Decode model to predict whether to put something in the summary graph or not using only the word ids as features, but realized it would probably be more sufficient to also use the POS tags.

I also experimented with different loss functions, but for now i decided to use softmax cross entropy with output feature sizes of 2.

Training on more, than 7000 articles for 5 epochs (Early stopping stopped it from running any longer) I've got the following results.
\begin{table}[!h]
	\centering
	\begin{tabular}{| c | c |}
		\hline
		Test loss & 0.447 \\ \hline
		Test accuracy over nodes and edges & 0.958 \\ \hline
		Test accuracy over full graphs & 0.0 \\ \hline
	\end{tabular}
	\caption{Softmax cross entropy loss and accuracy on the test set}
\end{table}

\begin{table}[!h]
	\centering
	\begin{tabular}{| c | c | c | c |}
		\hline
		 & precision & recall & f1 \\ \hline \hline
		edges labeled 0&0.96&1.0&0.98  \\ \hline
		edges labeled 1 & 0.0 & 0.0 & 0.0 \\ \hline
		nodes labeled 0 & 0.915 & 0.985 & 0.949 \\ \hline
		nodes labeled 1 & 0.628 & 0.213 & 0.319 \\ \hline
	\end{tabular}
	\caption{The classification report on the test set. Nodes and edges labeled 1 are the ones that were in the summary.}
\end{table}

As it is clear from this the network hardly ever classifies a node as "1", meaning that is should be in the summary graph, but when it does it is 62.8\% accurate.

This model has not been further evaluated.

\subsection{SimpleGraphAttention Network}
I trained the network on the whole training set (80\% of the whole dataset) for 3 epochs. It stopped after the third epoch because of the early stopping mechanism.

I evaluated the trained network on the test set and the results are the following:

\begin{table}[!h]
	\centering
	\begin{tabular}{| c | c |}
		\hline
		Test loss & 0.809 \\ \hline
		Test accuracy over nodes and edges& 0.724 \\ \hline
		Test accuracy over full graphs & 0.0 \\ \hline
	\end{tabular}
	\caption{Softmax cross entropy loss and accuracy on the test set}
\end{table}

\begin{table}[!h]
	\centering
	\begin{tabular}{| c | c | c | c |}
		\hline
		& precision & recall & f1 \\ \hline \hline
		nodes labeled 0 & 0.819 & 0.814 & 0.816 \\ \hline
		nodes labeled 1 & 0.534 & 0.542 & 0.538 \\ \hline
	\end{tabular}
	\caption{The classification report on the test set. Nodes and edges labeled 1 are the ones that were in the summary.}
\end{table}

\subsubsection{Summary reconstruction and evaluation}
I tried three different approaches at the summary extraction, each have been evaluated by the ROUGE scoring mechanism. For this I used the perl based pyrouge package.

\paragraph{Reconstruction with the node average}

This reconstruction method scores each sentence of the original article using the equation below where the \(score_{word}\) is the predicted probability of the word (node) being in the summary graph.

\[score_{sentence} = \frac{\sum_{word \in sentence\ and\ word \notin stopwords} score_{word}}{|word \in sentence\ and\ word \notin stopwords|}\]

Based on the calculated score of each sentence we can order them by their relevance and keep the four most relevant sentence from the article as the summary.

This method does not utilize the information of the graph structure nor does it prefer longer sentences.

\begin{longtable}{| l | l | l | l | l |}
	\hline
	\textbf{Evaluation method}&\textbf{Metric}&\textbf{System}&\textbf{Gensim}&\textbf{Extracted}\\ \hline \hline		
	\multirow{3}{*}{\textbf{ROUGE-1}}
		&Average Recall&0.39057&0.56350&0.73912 \\
		&Average Precision&0.23650&0.20366&0.33846 \\ 
		&Average F1&0.27641&0.28692&0.44619 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-2}}
		&Average Recall&0.12562&0.20801&0.39292 \\
		&Average Precision&0.07189&0.07546&0.18290 \\
		&Average F1&0.08597&0.10587&0.23900 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-3}}
		&Average Recall&0.06508&0.11009&0.246448 \\
		&Average Precision&0.03694&0.04068&0.11801 \\
		&Average F1&0.04424&0.05656&0.15226 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-4}}
		&Average Recall&0.04171&0.07074&0.17230 \\
		&Average Precision&0.02395&0.02666&0.08483 \\
		&Average F1&0.02846&0.03671&0.10807 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-L}}
		&Average Recall&0.24031&0.34467&0.51007 \\
		&Average Precision&0.14231&0.12093&0.23272 \\
		&Average F1&0.16713&0.17149&0.30654 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-W-1.2}}
		&Average Recall&0.09211&0.12907&0.19517 \\
		&Average Precision&0.11261&0.09360&0.18583 \\
		&Average F1&0.09242&0.10068&0.17739 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-S*}}
		&Average Recall&0.14421&0.27925&.48162 \\
		&Average Precision&0.05248&0.04148&0.11587 \\
		&Average F1&0.06344&0.06513&0.16621 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-SU*}}
		&Average Recall&0.15604&0.29271&0.49149 \\
		&Average Precision&0.05775&0.04401&0.12013 \\
		&Average F1&0.06957&0.06914&0.17242 \\ \hline
	\caption{ROUGE scores on the test set with reconstruction method using only the node scores}
\end{longtable}

\paragraph{Reconstruction with just the graph structure}

Contrary to the previous version this construction method does not use the output of the graph neural network but it is included here as contrast and as a step toward the next summarization method.

\begin{eqnarray*}
	score_{sentence} = \sum_{edge \in sentence\ graph} &[1\ if\ sender\ word \notin stopwords] + \\&[1\ if\ receiver\ word \notin stopwords]
\end{eqnarray*}

The ordering is based on this score. The summary contains the four best sentences.

\begin{longtable}{| l | l | l | l | l |}
	\hline
	\textbf{Evaluation method}&\textbf{Metric}&\textbf{System}&\textbf{Gensim}&\textbf{Extracted}\\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-1}}
		&Average Recall&0.54166&0.56350&0.73912 \\
		&Average Precision&0.18856&0.20366&0.33846 \\ 
		&Average F1&0.26990&0.28692&0.44619 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-2}}
		&Average Recall&0.18824&0.20801&0.39292 \\
		&Average Precision&0.06688&0.07546&0.18290 \\
		&Average F1&0.09491&0.10587&0.23900 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-3}}
		&Average Recall&0.09844&0.11009&0.246448 \\
		&Average Precision&0.03593&0.04068&0.11801 \\
		&Average F1&0.05042&0.05656&0.15226 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-4}}
		&Average Recall&0.06315&0.07074&0.17230 \\
		&Average Precision&0.02365&0.02666&0.08483 \\
		&Average F1&0.03282&0.03671&0.10807 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-L}}
		&Average Recall&0.32680&0.34467&0.51007 \\
		&Average Precision&0.11053&0.12093&0.23272 \\
		&Average F1&0.15918&0.17149&0.30654 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-W-1.2}}
		&Average Recall&0.12214&0.12907&0.19517 \\
		&Average Precision&0.08543&0.09360&0.18583 \\
		&Average F1&0.09396&0.10068&0.17739 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-S*}}
		&Average Recall&0.25325&0.27925&.48162 \\
		&Average Precision&0.03534&0.04148&0.11587 \\
		&Average F1&0.05684&0.06513&0.16621 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-SU*}}
		&Average Recall&0.26694&0.29271&0.49149 \\
		&Average Precision&0.03758&0.04401&0.12013 \\
		&Average F1&0.06048&0.06914&0.17242 \\ \hline
	\caption{ROUGE scores on the test set with reconstruction method using just the graph structure}
\end{longtable}

\paragraph{Reconstruction with the graph structure and the node scores}

This method is the blend of the previous two. It utilizes the structure of the graph but also uses the output of the graph neural network.
\begin{eqnarray*}
	score_{sentence} = \sum_{edge \in sentence\ graph} &[score_{sender\ word}\ if\ sender\ word \notin stopwords] + \\&[score_{receiver\ word}\ if\ receiver\ word \notin stopwords]
\end{eqnarray*}
\begin{longtable}{| l | l | l | l | l |}
	\hline
	\textbf{Evaluation method}&\textbf{Metric}&\textbf{System}&\textbf{Gensim}&\textbf{Extracted}\\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-1}}
		&Average Recall&0.56795&0.56350&0.73912 \\
		&Average Precision&0.21344&0.20366&0.33846 \\ 
		&Average F1&0.29885&0.28692&0.44619 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-2}}
		&Average Recall&0.21968&0.20801&0.39292 \\
		&Average Precision&0.08345&0.07546&0.18290 \\
		&Average F1&0.11608&0.10587&0.23900 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-3}}
		&Average Recall&0.11917&0.11009&0.246448 \\
		&Average Precision&0.04626&0.04068&0.11801 \\
		&Average F1&0.06368&0.05656&0.15226 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-4}}
		&Average Recall&0.07688&0.07074&0.17230 \\
		&Average Precision&0.03053&0.02666&0.08483 \\
		&Average F1&0.03282&0.04157&0.10807 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-L}}
		&Average Recall&0.34952&0.34467&0.51007 \\
		&Average Precision&0.12771&0.12093&0.23272 \\
		&Average F1&0.17993&0.17149&0.30654 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-W-1.2}}
		&Average Recall&0.13174&0.12907&0.19517 \\
		&Average Precision&0.09944&0.09360&0.18583 \\
		&Average F1&0.10571&0.10068&0.17739 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-S*}}
		&Average Recall&0.28093&0.27925&.48162 \\
		&Average Precision&0.04521&0.04148&0.11587 \\
		&Average F1&0.07070&0.06513&0.16621 \\ \hline \hline
	\multirow{3}{*}{\textbf{ROUGE-SU*}}
		&Average Recall&0.29450&0.29271&0.49149 \\
		&Average Precision&0.04788&0.04401&0.12013 \\
		&Average F1&0.07492&0.06914&0.17242 \\ \hline
	\caption{ROUGE scores on the test set with reconstruction method using both graph structure and the node scores}
\end{longtable}

\subsubsection{Example}
To better visualize the results I compare the summary graph from Chapter~\ref{sect:DataProcessing} (Figure~\ref{fig:usain_summary_graph} and) to the calculated graph (Figure~\ref{fig:usain_bolt_predicted0}). The generated summaries are also written below.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=150mm, keepaspectratio]{figures/usain_bolt_predicted.png}
	\caption{The calculated summary graph of the example article with just the nodes labeled 1.}
	\label{fig:usain_bolt_predicted0}
\end{figure}

\textbox{
	\textbf{Reconstruction with the node average}
	
	Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay.
	Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.
	The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team.
	Bolt's final dash for golden glory brought the eight-day championship to a rousing finale, but while the hosts topped the medal table from the United States there was criticism of the poor attendances in the Luzhniki Stadium.
	
	\textbf{Reconstruction with just the graph structure}
	
	The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles.
	Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple.
	The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.
	Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover.
	
	\textbf{Reconstruction with the graph structure and the node scores}
	
	The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.
	Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover.
	Germany's Christina Obergfoll finally took gold at global level in the women's javelin after five previous silvers, while Kenya's Asbel Kiprop easily won a tactical men's 1500m final.
	Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple.}{
	\caption{Example article summaries}}

\subsection{GraphAttention Network}
\subsubsection{Example}
Similarly to the previous case I compared the summary graph from Chapter~\ref{sect:DataProcessing} (Figure~\ref{fig:usain_summary_graph} and) to the calculated graph (Figure~\ref{fig:usain_bolt_predicted1}). The generated summaries are also written below.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=150mm, keepaspectratio]{figures/usain_bolt_predicted_attended.png}
	\caption{The calculated summary graph of the example article with just the nodes labeled 1.}
	\label{fig:usain_bolt_predicted1}
\end{figure}

\textbox{
	\textbf{Reconstruction with the node average}
	
	Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.
	Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay.
	The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team.
	The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.
	
	\textbf{Reconstruction with just the graph structure}
	
	The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles.
	Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple.
	The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.
	Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover.
	
	\textbf{Reconstruction with the graph structure and the node scores}
	
	The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.
	Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover.
	Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple.
	Germany's Christina Obergfoll finally took gold at global level in the women's javelin after five previous silvers, while Kenya's Asbel Kiprop easily won a tactical men's 1500m final.}{}